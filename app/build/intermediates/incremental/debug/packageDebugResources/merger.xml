<?xml version="1.0" encoding="utf-8"?>
<merger version="3"><dataSet aapt-namespace="http://schemas.android.com/apk/res-auto" config="main$Generated" generated="true" ignore_pattern="!.svn:!.git:!.ds_store:!*.scc:.*:&lt;dir>_*:!CVS:!thumbs.db:!picasa.ini:!*~"><source path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res"/><source path="/home/timon/AndroidStudioProjects/Machine_learning/app/build/generated/res/rs/debug"/><source path="/home/timon/AndroidStudioProjects/Machine_learning/app/build/generated/res/resValues/debug"/></dataSet><dataSet aapt-namespace="http://schemas.android.com/apk/res-auto" config="main" generated-set="main$Generated" ignore_pattern="!.svn:!.git:!.ds_store:!*.scc:.*:&lt;dir>_*:!CVS:!thumbs.db:!picasa.ini:!*~"><source path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res"><file path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/values-w600dp/dimens.xml" qualifiers="w600dp-v13"><dimen name="fab_margin">48dp</dimen></file><file name="activity_tipslearnings" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/activity_tipslearnings.xml" qualifiers="" type="layout"/><file name="activity_settings" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/activity_settings.xml" qualifiers="" type="layout"/><file name="activity_classtask" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/activity_classtask.xml" qualifiers="" type="layout"/><file name="activity_workneuro" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/activity_workneuro.xml" qualifiers="" type="layout"/><file name="activity_examples" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/activity_examples.xml" qualifiers="" type="layout"/><file name="activity_begtest" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/activity_begtest.xml" qualifiers="" type="layout"/><file name="activity_main" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/activity_main.xml" qualifiers="" type="layout"/><file name="activity_tipstest" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/activity_tipstest.xml" qualifiers="" type="layout"/><file name="activity_beginning" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/activity_beginning.xml" qualifiers="" type="layout"/><file name="nav_header" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/nav_header.xml" qualifiers="" type="layout"/><file path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/values/colors.xml" qualifiers=""><color name="black2">#FF222222</color><color name="background">#000000</color><color name="teal_200">#FF03DAC5</color><color name="teal_700">#FF018786</color><color name="black">#FF000000</color><color name="white">#FFFFFFFF</color><color name="white_theme">#CCCCCC</color><color name="white_text">#B8B8B8</color><color name="black_text">#191919</color><color name="white_line">#B6B6B6</color><color name="black_line">#202020</color><color name="link">#005F9E</color><color name="code">#369E00</color><color name="up_bar_day">#0055FF</color><color name="up_bar_night">#202020</color><color name="down_bar_day">#D3D3D3</color><color name="down_bar_night">#202020</color><color name="copy_button_back">#12141F</color><color name="fab_button">#6E6E6E</color><color name="button">#4B11D5</color></file><file path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/values/themes.xml" qualifiers=""><style name="Theme.Machine_learning" parent="Theme.MaterialComponents.DayNight.DarkActionBar">
        <item name="colorPrimaryVariant">@color/black_text</item>
        <item name="colorOnPrimary">@color/white</item>
        <item name="colorSecondary">@color/teal_200</item>
        <item name="colorSecondaryVariant">@color/teal_700</item>
        <item name="colorOnSecondary">@color/black</item>
    </style><style name="customDay.NoActionBar">
        <item name="windowActionBar">false</item>
        <item name="windowNoTitle">true</item>
    </style><style name="customDay.AppBarOverlay" parent="ThemeOverlay.AppCompat.Dark.ActionBar"/><style name="customDay.PopupOverlay" parent="ThemeOverlay.AppCompat.Light"/></file><file path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/values/dimens.xml" qualifiers=""><dimen name="activity_horizontal_margin">16dp</dimen><dimen name="activity_vertical_margin">16dp</dimen><dimen name="nav_header_vertical_spacing">8dp</dimen><dimen name="nav_header_height">176dp</dimen><dimen name="fab_margin">16dp</dimen></file><file path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/values/strings.xml" qualifiers=""><string name="app_name">Машинное обучение</string><string name="beginning">Введение</string><string name="tipslearnings">Виды обучения</string><string name="classtask">Задачи классификации и регрессии</string><string name="examples">Примеры</string><string name="back">←</string><string name="go">Далее</string><string name="test">Пройти тест</string><string name="learn_with_teacher">Обучение с учителем</string><string name="learn_without_teacher">Обучение без учителя</string><string name="learn_reinforcement">Обучение с подкреплением</string><string name="content">Содержание:</string><string name="smile">Смайлик:</string><string name="change_theme">Смена темы</string><string name="gmail">neuralguyy@gmail.com</string><string name="copy">Копировать</string><string name="linear">Линейная</string><string name="not_linear">Не линейная</string><string name="settings">Настройки</string><string name="font_size">Размер шрифта</string><string name="language">Язык</string><string name="font">Шрифт</string><string name="one_ten">1/10</string><string name="two_ten">2/10</string><string name="three_ten">3/10</string><string name="four_ten">4/10</string><string name="five_ten">5/10</string><string name="six_ten">6/10</string><string name="seven_ten">7/10</string><string name="eight_ten">8/10</string><string name="nine_ten">9/10</string><string name="ten_ten">10/10</string><string name="one_five">1/5</string><string name="two_five">2/5</string><string name="three_five">3/5</string><string name="four_five">4/5</string><string name="five_five">5/5</string><string name="greeting">Приветствую, дорогой читатель!</string><string name="start_text">Данное приложение поможет тебе освоить основные концепции машинного обучения практически с
        нуля. В процессе чтения станут ясны такие объёмные темы, как: история зарождения машинного обучения, виды обучения
        моделей для конкретных задач, работа нейросетей и ещё много объёмных тем.</string><string name="beginning_menu1"><u>1. История</u></string><string name="beginning_menu2"><u>2. Актуальность</u></string><string name="beginning_menu3"><u>3. Требования</u></string><string name="beginning_history"><u>История</u></string><string name="frenk">Фрэнк Розенблатт</string><string name="artur">Артур Сэмуэл</string><string name="beginning_history_text1">Машинное обучение - это область искусственного интеллекта, в которой компьютерные
        алгоритмы учатся на основе данных, чтобы выполнять задачи без явного программирования. История машинного обучения
        насчитывает более полувека и связана с различными научными открытиями, технологическими прорывами и инновационными
        идеями. Первые шаги к созданию машинного обучения были сделаны в 1950-х годах, когда ученые начали исследовать, как
        компьютеры могут извлекать знания из данных. Одним из первых методов машинного обучения был перцептрон, созданный
        Фрэнком Розенблаттом в 1957 году. Он был представлен как искусственная нейронная сеть, способная распознавать образы.</string><string name="beginning_history_text2">В 1960-х годах Ричард Стивенсон разработал теорию структурного обучения, которая давала
        возможность машинам обучаться на основе классификации и оценки данных. В это же время Артур Сэмуэл начал исследовать
        игру шашки и создал первую программу для игры в них, способную учиться на своих ошибках и становиться более эффективной с каждой игрой.</string><string name="beginning_history_text3">В 1970-х годах развивались
        методы классификации и кластеризации, а также создавались первые экспертные системы. На этом этапе машинное обучение
        получило новый импульс благодаря появлению новых методов оптимизации и статистического анализа.В 1980-х годах машинное
        обучение стало приобретать все большую популярность, особенно в области распознавания речи и компьютерного зрения. В
        этот период было разработано много алгоритмов, которые стали широко используемыми в машинном обучении.В 1990-х годах
        машинное обучение продолжило свое развитие и получило новые возможности благодаря появлению интернета и большого
        количества данных. Были созданы новые методы машинного обучения, такие как генетические алгоритмы, а также методы
        глубокого обучения, основанные на использовании искусственных нейронных сетей с несколькими слоями. Эти методы стали
        широко применяться в различных областях, таких как обработка естественного языка, распознавание образов и анализ данных.В
        2000-х годах машинное обучение продолжило свое развитие и получило новые возможности благодаря использованию больших
        данных и вычислительной мощности. Были созданы новые методы обучения с подкреплением.</string><string name="beginning_relevance"><u>Актуальность</u></string><string name="beginning_relevance_text">Сегодня машинное обучение широко
        используется в различных областях, включая медицину, финансы, производство и транспорт. Оно позволяет компаниям и
        организациям извлекать ценную информацию из больших объемов данных и принимать более эффективные решения. Однако, как и
        любая технология, машинное обучение имеет свои ограничения и вызывает вопросы в области этики и безопасности. Например,
        вопросы об использовании персональных данных и автономных систем, а также о возможности создания алгоритмов, которые
        могут быть приведены в действие непреднамеренно. В целом, машинное обучение является быстроразвивающейся областью,
        которая продолжает трансформировать наш мир. Оно открывает новые возможности и решает сложные проблемы, но требует
        внимательного рассмотрения и бдительности в отношении его использования.</string><string name="beginning_requirements"><u>Требования</u></string><string name="beginning_requirements_text">Для ознакомления потребуется:
        \n1. Знать синтаксис языка программирования python
        \n2. Владеть основами математического анализа, теории вероятностей и линейной алгебры
        \n3. Тяга к изучению данного направления</string><string name="beginning_test_question1">Кто создал перцептрон?</string><string name="beginning_test_answer11">Фернан Лекант</string><string name="beginning_test_answer12">Артур Сэмуэл</string><string name="beginning_test_answer13">Фрэнк Розенблатт</string><string name="beginning_test_answer14">Том Эстрем</string><string name="beginning_test_question2">В каких годах были сделаны первые шаги в развитии данной области?</string><string name="beginning_test_answer21">В 1940-х</string><string name="beginning_test_answer22">В 1950-х</string><string name="beginning_test_answer23">В 1960-х</string><string name="beginning_test_answer24">В 1970-х</string><string name="beginning_test_question3">К какой игре раньше всего применили методы машинного обучения?</string><string name="beginning_test_answer31">Шахматы</string><string name="beginning_test_answer32">Пинг-понг</string><string name="beginning_test_answer33">Марио</string><string name="beginning_test_answer34">Шашки</string><string name="beginning_test_question4">Что необходимо для обучения нейросетей?</string><string name="beginning_test_answer41">Большой объём обучающих данных</string><string name="beginning_test_answer42">Большие вычислительные мощности</string><string name="beginning_test_answer43">Много времени</string><string name="beginning_test_answer44">Всё перечисленное</string><string name="beginning_test_question5">Почему используют нейросети?</string><string name="beginning_test_answer51">С их помощью можно решать нестандартные задачи</string><string name="beginning_test_answer52">Их очень просто и быстро делать</string><string name="beginning_test_answer53">Это прикольно🙃</string><string name="beginning_test_answer54">Они со всем справляются лучше обычных алгоритмов</string><string name="tipslearnings_menu1"><u>1. Немного о данных</u></string><string name="tipslearnings_menu2"><u>2. Обучение с учителем</u></string><string name="tipslearnings_menu3"><u>3. Обучение без учителя</u></string><string name="tipslearnings_with_teacher"><u>Обучение с учителем</u></string><string name="tipslearnings_with_teacher_text">Обучение с учителем является самым распространнёным видом обучения моделей.
        Это обусловлено тем, что он самый простой в понимании и реализации. Этот способ применяется в задачах, в которых мы хотим
        точно научить модель выполнять одну конкретную задачу, например: классификация и сегментация объектов на фото,
        распознавание спама, генерация текста, синтез речи, генерация и описание изображений и тд. Принцип этого
        способа заключается в том, что модели подаётся много тренировочных данных, модель обучается и начинает делать прогнозы. Данные могут
        быть самыми разными. Это зависит от цели задачи. В начале процесса она делает прогнозы случайно, пытаясь предугадать
        желаемый результат. После каждой попытки её прогноз сравнивается с реальным прогнозом, то есть тем, который мы хотим от
        неё получить и вычисляется разница между ними. Данные мы можем подавать ей одни и те же по несколько раз, но в таком
        случае нужно избегать переобучения. Переобучение - это ситуация, когда модель просто запоминает обучающие данные и
        прекрасно их прогнозирует, однако на новых данных она работает плохо, тем самым теряет обощающую способность, что
        очень плохо. Представьте что вы обучили модель различать яблоки
        на фото. Для этого вы использовали 1000 фото, при переобучении она будет распознавать яблоки только на этих
        фото, но с другими фото она будет работать неисправно. Более детально про переобучение и как его избежать описано в главе
        про работу нейронных сетей. Таким образом, метод заключается в том, что мы показываем модели правильный результат после
        каждой её попытки, она обучается и пытается в дать лучший прогноз в следущий раз.</string><string name="tipslearnings_with_teacher_plus"><b>Преимущества</b>:
        \n1. Относительно лёгкая реализация
        \n2. Высокая эффективность
        \n3. Широкий спектр применения</string><string name="tipslearnings_with_teacher_minus"><b>Недостатки</b>:
        \n1. Необходимо большое количество подготовленных данных
        \n2. Большие вычислительные затраты
        \n3. Есть риск переобучения</string><string name="tipslearnings_without_teacher"><u>Обучение без учителя</u></string><string name="tipslearnings_without_teacher_text">Обучение без учителя категорически отличается от предыдущего способа.
        Здесь модель получает данные, но не получает ответа на них, а вместо этого пытается найти среди них закономерности.
        Этот метод используется для систем рекомендаций, анализа данных в социальных сетях, медицинских анализов и во многих
        других сферах.</string><string name="tipslearnings_without_teacher_plus"><b>Преимущества</b>:
        \n1. Нет нужды в больших объёмах данных, предварительно размеченных для обучения
        \n2. Возможность автоматической обработки большого количества данных без привязки к заранее заданной модели или классификации
        \n3. Возможность обнаружения новых паттернов в данных</string><string name="tipslearnings_without_teacher_minus"><b>Недостатки</b>:
        \n1. Нет гарантии, что полученные результаты будут иметь практическое применение или смысл
        \n2. Нет явной цели или задачи для модели, что может затруднять интерпретацию полученных результатов
        \n3. Модели машинного обучения без учителя могут быть сложными и могут потребовать большого количества вычислительных ресурсов</string><string name="tipslearnings_reinforcement"><u>Обучение с подкреплением</u></string><string name="tipslearnings_reinforcement_text">Обучение с подкреплением является самым сложным в реализации и внедрении.
        В данном случае модель называется агентом, который помещается в некую среду. Среда может быть физической
        (например игрой) или абстрактной (например, алгоритмической задачей). Агент совершает какие-то действия, изучая среду.
        За некоторые действия он получает награду в виде очков, а за некоторые наказание в виде снятия очков. Смысл в том, что
        агент пытается набрать как можно больше очков. Для этого ему нужно будет выполнять определённые действия, которые
        определяем мы. Рассмотрим игру змейка, в ней за каждое съеденное яблоко агент будет получать награду, а за каждую
        смерть наказание. Со временем он научится хорошо выполнять поставленную задачу, благодаря анализу своих предыдущих
        действий и корректировке последующих. Этот алгоритм обучения является самым сложным, но самым интересным и перспективным. Этот метод используется в робототехнике, на финансовых рынках, а также с высокой вероятностью будет использоваться в будущем для логики живых существ в играх</string><string name="tipslearnings_reinforcement_plus"><b>Преимущества</b>:
        \n1. Можно решать задачи, для которых сложно или невозможно создать точную математическую модель
        \n2. Алгоритмы обучения с подкреплением могут самостоятельно находить оптимальные стратегии поведения в среде, без предварительного знания о структуре среды</string><string name="tipslearnings_reinforcement_minus"><b>Недостатки</b>:
        \n1. Долгое обучение
        \n2. Обучение с подкреплением требует многократного взаимодействия с окружающей средой, чтобы получить достаточное количество обучающих примеров
        \n3. Множество параметров, которые нужно настроить для лучшего результата</string><string name="tipslearnings_test_question1">Какой самый распростанённый способ обучения?</string><string name="tipslearnings_test_answer11">Обучение с учителем</string><string name="tipslearnings_test_answer12">Обучение без учителя</string><string name="tipslearnings_test_answer13">Обучение с подкреплением</string><string name="tipslearnings_test_answer14">Они используются с одинаковой частотой</string><string name="tipslearnings_test_question2">Кто создал перцептрон?</string><string name="tipslearnings_test_answer21">Фернан Лекант</string><string name="tipslearnings_test_answer22">Артур Сэмуэл</string><string name="tipslearnings_test_answer23">Фрэнк Розенблатт</string><string name="tipslearnings_test_answer24">Том Эстрем</string><string name="tipslearnings_test_question3">Кто создал перцептрон?</string><string name="tipslearnings_test_answer31">Фернан Лекант</string><string name="tipslearnings_test_answer32">Артур Сэмуэл</string><string name="tipslearnings_test_answer33">Фрэнк Розенблатт</string><string name="tipslearnings_test_answer34">Том Эстрем</string><string name="tipslearnings_test_question4">Кто создал перцептрон?</string><string name="tipslearnings_test_answer41">Фернан Лекант</string><string name="tipslearnings_test_answer42">Артур Сэмуэл</string><string name="tipslearnings_test_answer43">Фрэнк Розенблатт</string><string name="tipslearnings_test_answer44">Том Эстрем</string><string name="tipslearnings_test_question5">Кто создал перцептрон?</string><string name="tipslearnings_test_answer51">Фернан Лекант</string><string name="tipslearnings_test_answer52">Артур Сэмуэл</string><string name="tipslearnings_test_answer53">Фрэнк Розенблатт</string><string name="tipslearnings_test_answer54">Том Эстрем</string><string name="classtask_menu1"><u>1. Классификация</u></string><string name="classtask_menu2"><u>2. Обучение модели</u></string><string name="classtask_menu3"><u>3. Регрессия</u></string><string name="classification"><u>Классификация</u></string><string name="fit_model"><u>Обучение модели</u></string><string name="classification_text1">Прежде всего стоит упомянуть, что классификацию иногда называют логистической
    регрессией, помимо неё есть линейная регрессия. В дальнейшем под классификацией я буду подразумевать логистическую
    регрессию, а просто регрессией буду называть именно линейную. Классификация и регрессия - это задачи машинного
    обучения. Обе эти задачи относятся к обучению с учителем, а значит нам нужны данные для обучения модели. Классификация -
    это задача, в которой нам нужно отнести объект к одному из классов, учитывая характеристики  данного объекта.
    Предположим что нам нужно определить вероятность поступления школьника в университет, для этого будем ориентироваться
    на его баллы за егэ. У нас есть большой список, в котором множество вложенных списков с баллами ученика по разным
    предметам и нам нужно обучить модель на основе этих данных. Для этого разберём принцип обучения моделей.</string><string name="classification_text2">С этого момента начинаются фрагменты с кодом, советую поэтапно повторять все
    действия, для лучшего закрепления материала.</string><string name="classification_comment1">Для начала необходимо установить библиотеку numpy, выполнив команду в терминале:</string><string name="classification_code1">pip install numpy</string><string name="classification_comment2">Затем создадим класс нашей будущей модели:</string><string name="classification_code2">class Classification:
    \n\tdef __init__(self, learning_rate=0.01, num_iterations=1000):
        \n\tself.learning_rate = learning_rate
        \n\tself.num_iterations = num_iterations
        \n\tself.weights = None
        \n\tself.bias = None</string><string name="classification_text3">Здесь </string><string name="workneuro_menu1"><u>1. Что такое нейросеть</u></string><string name="workneuro_menu2"><u>2. Функции активации</u></string><string name="workneuro_menu3"><u>3. Виды функций активации</u></string><string name="perceptron">Перцептрон</string><string name="neuron">Нейрон</string><string name="whats_neural_network">Что такое нейросеть</string><string name="neural_work">Работа нейронной сети</string><string name="whats_neural_network_text1">Нейросеть, как исходит из названия, состоит из множества слоёв нейронов, которые связаны между
    собой. Благодаря этим связям, нейроны передают друг другу некоторую информацию. Каждый нейрон принимает информацию от
    предыдущего нейрона, изменяет её и отдаёт следующему. Самый первый слой нейросети называется входным слоем, он принимает
    на вход данные. Последний слой нейросети называется выходным, так как он возвращает итоговые данные. Все слои между первым
    и последним называются скрытыми, потому что их значения не наблюдаются напрямую в процессе обучения или использования
    нейронной сети. Количество слоёв в нейросети и количество нейронов в них определяет разработчик, их может быть сколько угодно,
    но абсолютно всегда нужно стараться брать минимально необходимое количество для решения задачи. О причинах этого мы поговорим
    чуть позже.</string><string name="whats_neural_network_text2">На схеме выше представлена самая простая нейросеть, которая называется "Перцептрон". Она
    состоит из входного слоя, одного скрытого и выходного. Каждый нейрон представлен кругом для простоты восприятия.
    Единственная информация, которой могут обмениваться нейроны - это числа. Передаваемые значения меняются, проходя через
    каждый нейрон по определённым правилам. Число, получившееся в предыдущем нейроне, умножается на вес следующего нейрона,
    и к этому произведению добавляется смещение нейрона. Весь этот процесс называют суммированием. В результате работы
        нейронов мы получаем конечный выход нейросети. Что же такое вес и смещение? Это просто числовые коэффициенты,
        которые имеет каждый нейрон. Вес нейрона обозначается буквой w(Weight), а смещение буквой b(Bias). Обратимся к схеме
        выше: нейрон N1 передаёт значение в каждый нейрон следующего слоя: N3, N4, N5. Рассмотрим действие на примере
        взаимодействия с N3. Предположим, что на вход нейрону N1 подаётся значение 1, это значение умножается на вес N1 - w1,
        прибавляется смещение N1 - b1 и это значение пропускается через функцию активации. Функции активации будут рассмотрены
        чуть позже. Далее полученный результат передаётся
        в нейрон N3. Значение 1 умножается на вес нейрона N3 - w3
        и прибавляется смещение N3 - b3. После N3 передаёт значение в
        последующие нейроны и так далее. Откуда брать значения весов и смещений? Нейросети могут состоять из миллиардов
        нейронов, так что подобрать коэффициенты вручную попросту невозможно, поэтому, изначально веса и смещения
        заполняют случайными числами(которые обычно находятся в пределах от 0 до 1), а затем меняют при обучении. Нахождение
        оптимальных коэффициентов весов и смещений - в
        этом и заключается задача обучения нейросетей. Наша цель - обучить нейросеть так, чтобы подобрать такие коэффициенты,
        благодаря которым наша нейросеть выдавала бы нам правильный результат. Если на данном этапе что-то не понятно, то не
        стоит переживать, всё станет яснее в ходе практики.
    </string><string name="activation_function">Функции активации</string><string name="activation_function_text1">Пришло время поговорить про функции активации. Что это такое и зачем они нужны? При суммировании
        наши данные изменяются линейно, но этого не всегда достаточно, чтобы максимально точно обучить модель предсказывать данные.
        Функция активации - это просто математическая функция, которая нужна для того, чтобы внести нелинейность в процесс
        обучения нейронных сетей. Без нелинейности (т.е. если бы мы использовали только линейную функцию, например, f(x) = x),
        нейронная сеть свелась бы к простому линейному уравнению, и мы бы потеряли способность моделировать сложные
        нелинейные зависимости в данных. На графиках ниже точками представлены наши данные, а чертой обозначены прогнозы
        обученной модели.</string><string name="without_func">Прогнозы без функции активации</string><string name="with_func">Прогнозы с функцией активации</string><string name="activation_function_text2">Несложно заметить, что с применением функции активации, наша модель стала более гибкой и
        лучше подстроилась под данные.</string><string name="types_of_functions">Виды функций активации</string><string name="types_of_functions_text1">Существует большое множество различных функций активации. У каждой из них есть
    свои недостатки и минусы, поэтому к каждой задаче нужно применять наиболее подходящую. Рассмотрим самые популярные и часто
    используемые из них. Начнём с наиболее простой и известной - ReLu(Rectified Linear Unit).
    </string><string name="types_of_functions_text2">Эту функцию часто используют из-за её эффективности при обучении и простоты вычислений.
    Однако у ReLu есть один существенный недостаток, так называемые \"Мёртвые зоны\"(Dead Zones). Если в результате суммирования
    в нейроне получается значение, которое меньше или равно 0, то функция возвращает 0. Таким образом, этот нейрон становится
    бесполезным при вычислениях и как бы \"умирает\". Для решения этой проблемы придумали Leaky ReLu. Математически она выглядит так:
        f(x) = max(a*x, x). Здесь a - небольшое положительное число, которое обычно берётся в пределах от 0 до 0.5.
    </string><string name="types_of_functions_text3">Далее в очереди на рассмотрение у нас находится сигмоида(логистическая функция).
        Эта функция возвращает только значения от 0 до 1. Сигмоида используется в задачах бинарной
        классификации(когда нам нужно разделить данные на 2 класса). В данном случае мы используем сигмоиду на
        последнем слое, чтобы получить значение от 0 до 1. Далее, если например значение больше 0.5, то относим объект к одному
        классу, а если меньше, то к другому. Позже мы используем это на практике и всё станет яснее.</string><string name="types_of_functions_text4">Были перечислены далеко не все функции, их существует намного больше, но это
    самый распространённые из них.</string><string name="neurolearning_menu2"><u>2. Функции потерь</u></string><string name="howneurolearning">Механизм обучения</string><string name="neurolearning_menu1"><u>1. Механизм обучения</u></string><string name="about_neuro">О нейросетях</string><string name="neurolearning">Обучение нейросети</string><string name="backpropagation">Алгоритм Back Propagation</string><string name="backpropagation_text1">Back Propagation - это алгоритм, который позволяет нам корректировать веса нашей сети.
        Этот алгоритм назван так, потому что в основе его работы лежит продвижение и изменение весов в слоях с конца к началу.
        Это означает, что мы сначала прогоним данные напрямую через нашу сеть, а затем будем двигаться обратно и корректировать
        веса в выходном слое, затем в предпоследнем и так далее, пока не доберёмся
        до входного. А сейчас, рассмотрим полностью одну итерацию обучения нейронной сети. Представим самую простую нейросеть,
        у которой в каждом слое по 1 нейрону. Мы подали модели данные, которые прошли через неё. Рассмотрим 2 последних слоя
        нейросети. Буквой a обозначим выход каждого нейрона. Над каждым выходом обозначен номер нейрона. У последнего номер равен
        L, у предыдущего L-1 и так далее.
    </string><string name="howneurolearning_text1">Мы поняли, что нам необходимо научить нашу нейросеть. Для этого нужно реализовать процесс
        обучения, в ходе которого её коэффициенты будут изменяться автоматически. Как же это осуществить? Мы будем использовать
        механизм обучения с учителем. Для этого мы сначала подадим на вход нашей модели обучающие данные. Эти данные как-то
        преобразуются, проходя через нейросеть, и на выходе мы получим результат. Далее получившиеся значения мы сравним с теми,
        что должны были получиться на самом деле, и найдём численную ошибку нейросети с помощью функции потерь.
        На основе этой ошибки мы и будем корректировать
        коэффициенты нейросети. Всё это происходит множество раз. Каждая итерация обучения называется эпохой(Epoch). Мы много раз
        проделываем вышеперечисленные шаги и постепенно регулируем весовые коэффициенты. Для нахождения оптимальных весов мы
        будем использовать алгоритм обратного распространения ошибки(Back Propagation).
    </string><string name="lossfunction_text1">Функция потерь - это функция, с помощью которой мы вычисляем ошибку нашей нейросети.
        Самой популярной является функция среднеквадратичной ошибки(Medium Squared Error - MSE).
    </string><string name="mse">Mean Squared Error</string><string name="neurolearning_menu3"><u>3. Алгоритм Back Propagation</u></string><string name="lossfunction">Функция потерь</string><string name="lossfunction_text2">Что означает каждая эта буква? Разберём по порядку:
        \nn - это количество объектов в наших данных
        \nY - целевое значение(то, которое нейросеть должна была предсказать)
        \nŶ - фактическое значение, которое получилось в результате предсказания сети.
        \nВ результате суммирования всех ошибок, мы получаем общую, на основе которой будем корректировать веса. Квадрат нам
    нужен для того, чтобы не получать отрицательных значений и ошибка всегда была положительной. </string><string name="tipslearnings_menu4"><u>4. Обучение с подкреплением</u></string><string name="aboutdata_text1">Данные - это главная вещь в машинном обучении, ведь без них оно просто не имеет смысла.
        У нас могут быть самые разнообразные данные в зависимости от задачи. Они представляют собой объекты и свойства(признаки).
        Проще всего представлять данные в виде таблицы. Свойства - это столбцы таблицы, объекты - это строки таблицы.
        Очень часто набор данных называют датасетом(Dataset). Датасеты могут быть представлены в различных форматах, таких как:
        CSV(Comma-Separated Values), JSON(JavaScript Object Notation), XLSX(Excel), XML(eXtensible Markup Language). Данные
        обычно разделяют на обучающие и тестовые. На обучающих данных обучают модель, а на тестовых её проверяют.
    </string><string name="aboutdata">Немного о данных</string><string name="data">Таблица с данными</string><string name="z">Преобразования в нейроне</string><string name="backpropagation_text5">Наглядно работу этого правила можно увидеть на схеме ниже</string><string name="backpropagation_text6">Вес нейрона меняется по следующей формуле</string><string name="last_neuro">Последние слои</string><string name="connections">Связь коэффициентов</string><string name="c">Вычисление ошибки</string><string name="backpropagation_text3">Буквой σ(Сигма) обозначена функция активации, которой в данном случае является сигмоида.
    Буквой z обозначен результат преобразования входа в нейроне</string><string name="backpropagation_text4">Для каждого полученного выхода нужно вычислить ошибку</string><string name="a">Выход нейрона</string><string name="backpropagation_text2">Далее распишем, как вычисляется параметр a</string><string name="backpropagation_text7">Здесь, параметр λ(Лямбда) - это показатель скорости обучения(learning rate). Он
        определяется вручную и влияет на то, как сильно меняются веса. О том, как его правильно подбирать, мы поговорим чуть
        позднее. А сейчас сконцентрируемся на непонятной дроби. Это отношение определяет то, насколько сильно ошибка зависит
    от данного веса. Иными словами, это просто показатель того как сильно изменяется ошибка, в зависимости от изменения веса.
    Именно для этого нам нужно найти частную производную C по w. Но напрямую мы сделать этого не можем, поэтому обратимся к
    цепному правилу(Chain rule). </string><string name="backpropagation_text8">Для того, чтобы понять то, как работает цепное правило, представим следующую ситуацию:
    предположим, что нам нужно узнать во сколько раз гепард быстрее человека. Мы этого не знаем, однако нам известно, что
    гепард быстрее льва в 2 раза, лев быстрее медведя в 2 раза, а медведь быстрее человека в 1.5 раза. Таким образом, мы можем
    найти разницу в скорости гепарда и человека</string><string name="update_w">Обновление веса нейрона</string><string name="chain_rule">Цепное правило</string><string name="chain_rule_explain">Объяснение цепного правила</string><string name="backpropagation_text11">Мы видим, что вторая производная равна производной функции активации, в нашем случае
    - сигмоиды. Ниже представлено вычисление функции сигмоиды. Запоминать вывод не обязательно, но стоит хотя бы иметь представление</string><string name="backpropagation_text10">Как можно видеть, первая производная равняется выходу предыдущего нейрона. Теперь
    разберёмся со второй</string><string name="backpropagation_text12">После вычисления производной, преобразуем её к более удобному виду</string><string name="backpropagation_text9">Теперь нам осталось лишь вычислить 3 частные производные, и мы сможем изменить вес
    нейрона. Выведем их все по порядку. Начнём с первой производной</string><string name="diff_log">Производная сигмоиды</string><string name="express_diff">Преобразования над производной</string><string name="der_3">Третья производная</string><string name="der_2">Вторая производная</string><string name="der_1">Первая производная</string><string name="backpropagation_text13">И теперь осталось вычислить последнюю производную</string><string name="neurolearning_menu4"><u>4. Скорость обучения</u></string><string name="backpropagation_text14">Ну вот и всё, поздравляю! Мы обновили весовой коэффициент в нейроне. Со всеми остальными
    нейронами это будет работать абсолютно также. А сейчас настало время поговорить про параметр лямбда.</string><string name="learning_rate_text1">Так для чего же нужен этот параметр лямбда и как его выбирать? В действительности это
    всего лишь маленькое число, которое определяет чувствительность весовых коэффициентов к ошибку. Обычно выбирается одно
    из нескольких значений: 0.1, 0.01, 0.001, 0.0001. Если взять этот коэффициент слишком маленьким, то наше обучение может
    протекать очень медленно, но мы же хотим затратить на обучение как можно меньше времени. С другой стороны, если этот
    параметр окажется слишком большим, то веса не смогут хорошо настроиться, а также увеличится риск переобучения модели.
        Это становится ясно, если посмотреть на проблему
    с точки зрения функций. Наша цель - это минимизировать ошибку, то есть найти минимум функции потерь. Однако, при низкой
    скорости обучения мы можем застрять в локальном минимуме, в то время, как мы хотим попасть в глобальный. Для определения
    наилучшего параметра используют либо автоматические инструменты, либо запускают несколько раз, и смотрят, с каким числом
    получаются наилучшие результаты. </string><string name="learning_rate">Скорость обучения</string><string name="examples1">Пример</string></file><file path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/values/styles.xml" qualifiers=""><style name="customNight" parent="Theme.AppCompat">
        <item name="android:textColor">@color/white_text</item>
        <item name="android:colorBackground">@color/background</item>
        <item name="android:navigationBarColor">@color/down_bar_night</item>
    </style><style name="customDay" parent="Theme.AppCompat.Light">
        <item name="android:textColor">@color/black_text</item>
        <item name="android:colorBackground">@color/white</item>
        <item name="android:navigationBarColor">@color/down_bar_day</item>
        <item name="android:actionBarTheme">@color/up_bar_day</item>
    </style><style name="defaultText">
        <item name="android:fontFamily">@font/kazmann</item>
        <item name="android:lineSpacingExtra">8dp</item>
        <item name="android:textSize">22sp</item>
        <item name="android:justificationMode">inter_word</item>
    </style><style name="linkText" parent="defaultText">
        <item name="android:textStyle">bold</item>
        <item name="android:textSize">30sp</item>
        <item name="android:textColor">@color/link</item>
    </style><style name="signature" parent="defaultText">
        <item name="android:textSize">16sp</item>
    </style><style name="copy_button" parent="defaultText">
        <item name="android:background">@color/copy_button_back</item>
        <item name="android:textColor">@color/code</item>
    </style><style name="button">
        <item name="background">@color/button</item>
    </style></file><file name="logo_96" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/mipmap-xhdpi/logo_96.webp" qualifiers="xhdpi-v4" type="mipmap"/><file name="data_extraction_rules" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/xml/data_extraction_rules.xml" qualifiers="" type="xml"/><file name="backup_rules" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/xml/backup_rules.xml" qualifiers="" type="xml"/><file name="ic_launcher_round" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/mipmap-anydpi-v26/ic_launcher_round.xml" qualifiers="anydpi-v26" type="mipmap"/><file name="ic_launcher" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/mipmap-anydpi-v26/ic_launcher.xml" qualifiers="anydpi-v26" type="mipmap"/><file name="neural_net" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/neural_net.jpg" qualifiers="" type="drawable"/><file name="perceptron" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/perceptron.jpg" qualifiers="" type="drawable"/><file name="sun" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/sun.png" qualifiers="" type="drawable"/><file name="sigmoid" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/sigmoid.jpg" qualifiers="" type="drawable"/><file name="not_linear" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/not_linear.jpg" qualifiers="" type="drawable"/><file name="artur" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/artur.jpg" qualifiers="" type="drawable"/><file name="rosenblatt" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/rosenblatt.jpg" qualifiers="" type="drawable"/><file name="back_main_night" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/back_main_night.jpg" qualifiers="" type="drawable"/><file name="relu" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/relu.jpg" qualifiers="" type="drawable"/><file name="up_arrow" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/up_arrow.xml" qualifiers="" type="drawable"/><file name="leaky_relu" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/leaky_relu.jpg" qualifiers="" type="drawable"/><file name="express_diff" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/express_diff.jpg" qualifiers="" type="drawable"/><file name="moon" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/moon.png" qualifiers="" type="drawable"/><file name="back_main_day" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/back_main_day.jpg" qualifiers="" type="drawable"/><file name="ic_launcher_background" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/ic_launcher_background.xml" qualifiers="" type="drawable"/><file name="linear" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/linear.jpg" qualifiers="" type="drawable"/><file name="back_7" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/back_7.jpg" qualifiers="" type="drawable"/><file name="diff_log" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/diff_log.jpg" qualifiers="" type="drawable"/><file name="round_button" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/round_button.xml" qualifiers="" type="drawable"/><file path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/values-land/dimens.xml" qualifiers="land"><dimen name="fab_margin">48dp</dimen></file><file name="kazmann" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/font/kazmann.ttf" qualifiers="" type="font"/><file name="logo_72" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/mipmap-hdpi/logo_72.webp" qualifiers="hdpi-v4" type="mipmap"/><file path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/values-w1240dp/dimens.xml" qualifiers="w1240dp-v13"><dimen name="fab_margin">200dp</dimen></file><file name="logo_144" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/mipmap-xxhdpi/logo_144.webp" qualifiers="xxhdpi-v4" type="mipmap"/><file path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/values-night/themes.xml" qualifiers="night-v8"><style name="Theme.Machine_learning" parent="Theme.MaterialComponents.DayNight.DarkActionBar">
        <item name="colorPrimaryVariant">@color/black_text</item>
        <item name="colorOnPrimary">@color/black</item>
        <item name="colorSecondary">@color/teal_200</item>
        <item name="colorSecondaryVariant">@color/teal_700</item>
        <item name="colorOnSecondary">@color/black</item>
    </style></file><file name="menu_main" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/menu/menu_main.xml" qualifiers="" type="menu"/><file name="menu_drawer" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/menu/menu_drawer.xml" qualifiers="" type="menu"/><file name="change_theme_animation" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/anim/change_theme_animation.xml" qualifiers="" type="anim"/><file name="logo_192" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/mipmap-xxxhdpi/logo_192.webp" qualifiers="xxxhdpi-v4" type="mipmap"/><file name="logo_48" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/mipmap-mdpi/logo_48.webp" qualifiers="mdpi-v4" type="mipmap"/><file name="ic_launcher_foreground" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable-v24/ic_launcher_foreground.xml" qualifiers="v24" type="drawable"/><file name="dehaze" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/dehaze.xml" qualifiers="" type="drawable"/><file name="rotate_animation" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/anim/rotate_animation.xml" qualifiers="" type="anim"/><file name="activity_neurolearning" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/layout/activity_neurolearning.xml" qualifiers="" type="layout"/><file name="mse" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/mse.jpg" qualifiers="" type="drawable"/><file name="data" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/data.jpg" qualifiers="" type="drawable"/><file name="a" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/a.jpg" qualifiers="" type="drawable"/><file name="c" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/c.jpg" qualifiers="" type="drawable"/><file name="chain_rule" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/chain_rule.jpg" qualifiers="" type="drawable"/><file name="connections" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/connections.jpg" qualifiers="" type="drawable"/><file name="last_neuro" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/last_neuro.jpg" qualifiers="" type="drawable"/><file name="z" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/z.jpg" qualifiers="" type="drawable"/><file name="chain_rule_explain" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/chain_rule_explain.jpg" qualifiers="" type="drawable"/><file name="update_w" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/update_w.jpg" qualifiers="" type="drawable"/><file name="der_1" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/der_1.jpg" qualifiers="" type="drawable"/><file name="der_2" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/der_2.jpg" qualifiers="" type="drawable"/><file name="der_3" path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/main/res/drawable/der_3.jpg" qualifiers="" type="drawable"/></source><source path="/home/timon/AndroidStudioProjects/Machine_learning/app/build/generated/res/rs/debug"/><source path="/home/timon/AndroidStudioProjects/Machine_learning/app/build/generated/res/resValues/debug"/></dataSet><dataSet aapt-namespace="http://schemas.android.com/apk/res-auto" config="debug$Generated" generated="true" ignore_pattern="!.svn:!.git:!.ds_store:!*.scc:.*:&lt;dir>_*:!CVS:!thumbs.db:!picasa.ini:!*~"><source path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/debug/res"/></dataSet><dataSet aapt-namespace="http://schemas.android.com/apk/res-auto" config="debug" generated-set="debug$Generated" ignore_pattern="!.svn:!.git:!.ds_store:!*.scc:.*:&lt;dir>_*:!CVS:!thumbs.db:!picasa.ini:!*~"><source path="/home/timon/AndroidStudioProjects/Machine_learning/app/src/debug/res"/></dataSet><dataSet aapt-namespace="http://schemas.android.com/apk/res-auto" config="generated$Generated" generated="true" ignore_pattern="!.svn:!.git:!.ds_store:!*.scc:.*:&lt;dir>_*:!CVS:!thumbs.db:!picasa.ini:!*~"/><dataSet aapt-namespace="http://schemas.android.com/apk/res-auto" config="generated" generated-set="generated$Generated" ignore_pattern="!.svn:!.git:!.ds_store:!*.scc:.*:&lt;dir>_*:!CVS:!thumbs.db:!picasa.ini:!*~"/><mergedItems/></merger>